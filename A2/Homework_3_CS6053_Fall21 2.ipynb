{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umNTUv2cfHeA"
   },
   "source": [
    "# Introduction to Data Science\n",
    "## Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GlW_q_DfHeF"
   },
   "source": [
    "Student Name: Pruthviraj R Patil\n",
    "\n",
    "Student Netid: \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ao4sbbN_fHeF"
   },
   "source": [
    "### Part 1 - Preparing a Training Set and Training a Decision Tree (Total 10 Points)\n",
    "This is a hands-on task where we build a predictive model using Decision Trees. For this part, we will be using the data in `cell2cell_data.csv`.\n",
    "\n",
    "These historical data consist of 39,859 customers: 19,901 customers that churned (i.e., left the company) and 19,958 that did not churn (see the `\"churndep\"` variable). Here are the dataset's 11 possible predictor variables for churning behavior: \n",
    "\n",
    "```\n",
    "Pos.  Var. Name  Var. Description\n",
    "----- ---------- --------------------------------------------------------------\n",
    "1     revenue    Mean monthly revenue in dollars\n",
    "2     outcalls   Mean number of outbound voice calls\n",
    "3     incalls    Mean number of inbound voice calls\n",
    "4     months     Months in Service\n",
    "5     eqpdays    Number of days the customer has had his/her current equipment\n",
    "6     webcap     Handset is web capable\n",
    "7     marryyes   Married (1=Yes; 0=No)\n",
    "8     travel     Has traveled to non-US country (1=Yes; 0=No)\n",
    "9     pcown      Owns a personal computer (1=Yes; 0=No)\n",
    "10    creditcd   Possesses a credit card (1=Yes; 0=No)\n",
    "11    retcalls   Number of calls previously made to retention team\n",
    "```\n",
    "\n",
    "The 12th column, the dependent variable `\"churndep\"`, equals 1 if the customer churned, and 0 otherwise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RinEl8tefHeG"
   },
   "source": [
    "1\\. Load the data and prepare it for modeling. Note that the features are already processed for you, so the only thing needed here is to split the data into training and testing. Use pandas to create two data frames: train_df and test_df, where train_df has 80% of the data chosen uniformly at random without replacement (test_df should have the other 20%). Also, make sure to write your own code to do the splits. You may use any random() function from numpy but do not use the data splitting functions from Sklearn.<br><br>\n",
    "\n",
    "(2 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "dSSp41-_fHeG"
   },
   "outputs": [],
   "source": [
    "#Place your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3glHFghUfHeH"
   },
   "source": [
    "2\\. Now build and train a decision tree classifier using `DecisionTreeClassifier()` [(manual page)](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) on train_df to predict the `\"churndep\"` target variable. Make sure to use `criterion='entropy'` when instantiating an instance of `DecisionTreeClassifier()`. For all other settings you should use all of the default options.\n",
    "\n",
    "(1 Point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "7SpcUFkBfHeI"
   },
   "outputs": [],
   "source": [
    "#Place your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KTkyj1zfHeI"
   },
   "source": [
    "3\\. Using the resulting model from 2.2, show a bar plot of feature names and their feature importance (hint: check the attributes of the `DecisionTreeClassifier()` object directly in IPython or check the manual!).\n",
    "\n",
    "(3 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "kVn_uirPfHeJ"
   },
   "outputs": [],
   "source": [
    "#Place your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngRqTE-cfHeK"
   },
   "source": [
    "4\\. Is the relationship between the top 3 most important features (as measured here) negative or positive? If your marketing director asked you to explain the top 3 drivers of churn, how would you interpret the relationship between these 3 features and the churn outcome?  What \"real-life\" connection can you draw between each variable and churn?\n",
    "\n",
    "(2 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "g6Z41fRNfHeK"
   },
   "outputs": [],
   "source": [
    "#Place your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZzahZM6fHeK"
   },
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "Place your response here\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzRMPRCDfHeL"
   },
   "source": [
    "5\\. Using the classifier built in 2.2, try predicting `\"churndep\"` on both the train_df and test_df data sets. What is the accuracy on each? Remember: accuracy is the fraction of predictions whose labels were gotten right by the model. What conclusions can you derive from this?\n",
    "\n",
    "(2 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "YHCy6vJ_fHeL"
   },
   "outputs": [],
   "source": [
    "#Place your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ja0wmZLAfHeL"
   },
   "source": [
    "### Part 2 - Finding a Good Decision Tree (Total 10 Points)\n",
    "The default options for your decision tree may not be optimal. We need to analyze whether tuning the parameters can improve the accuracy of the classifier.  For the following options `min_samples_split` and `min_samples_leaf`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-T1IkejfHeL"
   },
   "source": [
    "1\\. Generate a list of 10 values of each for the parameters min_samples_split and min_samples_leaf. \n",
    "\n",
    "(1 Point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSYV2Nr0fHeL"
   },
   "outputs": [],
   "source": [
    "#Place your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0KiM6aVfHeM"
   },
   "source": [
    "2\\. Explain what your reasoning was for choosing the above ranges.\n",
    "\n",
    "(1 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHFkW-zkfHeM"
   },
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "Place your response here\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuTpZs59fHeM"
   },
   "source": [
    "3\\. For each combination of values in 3.1 (there should be 100), build a new classifier and check the classifier's accuracy on the test data. Plot the test set accuracy for these options. Use the values of `min_samples_split` as the x-axis and generate a new series (line) for each of `min_samples_leaf`.\n",
    "\n",
    "(5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OVvaNvumfHeM"
   },
   "outputs": [],
   "source": [
    "#Place your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4Jq_QpbfHeM"
   },
   "source": [
    "4\\. Which configuration returns the best accuracy? What is this accuracy? (Note, if you don't see much variation in the test set accuracy across values of min_samples_split or min_samples_leaf, try redoing the above steps with a different range of values).\n",
    "\n",
    "(1 Point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "N0jS1pxIfHeM"
   },
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "Place your response here\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2YlEqsMfHeN"
   },
   "source": [
    "5\\. If you were working for a marketing department, how would you use your churn production model in a real business environment? Explain why churn prediction might be good for the business and how one might improve churn by using this model.\n",
    "\n",
    "(2 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLDVCCkAfHeN"
   },
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "Place your response here\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "kmz2Y192fHeN"
   },
   "source": [
    "### Part 3: Model selection with cross-validation (5 points)\n",
    "In this part, we will focus on cross-validation to find a good value for parameter `max_depth`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Q_757mQfHeN"
   },
   "source": [
    "1\\. Write a cross-validation function that does the following:\n",
    "- Takes as inputs a dataset, a label name, # of splits/folds (`k`), and a sequence of values for the maximum depth of the tree (`max_depth`). \n",
    "- Shuffles the data.\n",
    "- Splits the data into `k` folds according to the cross-validation logic\n",
    "- Performs two loops\n",
    "  - Outer Loop: `for each f in range(k)`:\n",
    "    - Inner Loop: `for each value in max_depth_sequence`:\n",
    "      - Trains a Decision Tree on the training split with the `max_depth=value` (USE criterion='entropy' BUT DO NOT ALTER THE OTHER PARAMETERS)\n",
    "      - Computes accuracy_value_f on test split\n",
    "      - Stores accuracy_value_f in a  dictionary of values\n",
    "- Returns a dictionary, where each key-value pair is: `value:[accuracy_value_1,...,accuracy_value_k]`\n",
    "\n",
    "(2 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H-eCX5rNfHeN"
   },
   "outputs": [],
   "source": [
    "#Place your code here\n",
    "#Uncomment line below\n",
    "#def xValDecisionTree(dataset, label_name, k, max_depth_sequence):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SwwXPi2VfHeN"
   },
   "source": [
    "2\\. Using the function written above, do the following:\n",
    "- Generate a sequence `max_depth_sequence = [None, 2, 4, 8, 16, 32, 128, 256, 512]` (Note that None is the default value for this parameter).\n",
    "2.\tCall accs = xValDecisionTree(dataset, 'churndep', 10, `max_depth_sequence`)\n",
    "3.  For each value in accs.keys(), calculate mean(accs[value]). What value is associated with the highest accuracy mean?\n",
    "4.  For each value in accs.keys(), calculate the ranges mean(accs[value]) +/- std(accs[value]). Do the ranges associated with the value that has the highest mean(accs[value]) overlap with ranges for other values? What may this suggest and what are the limitations of a standard deviation based analysis in this scenario?\n",
    "\n",
    "5.  Which depth value would you pick, if any, and why?\n",
    "\n",
    "(3 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DO7gTC5tfHeO"
   },
   "outputs": [],
   "source": [
    "#Place your code and answers here. You can create more cells if you want."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Homework_3_CS6053_Fall21.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
